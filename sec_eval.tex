\section{Evaluation}
\label{sec:eval}
To evaluate the effectiveness of \sysname{}, we present three test scenarios as case studies and compare \sysname{} with state-of-the-art solutions. These include:
\begin{enumerate}
    \item A comprehensive set of common misconfiguration types, where synthetic misconfigurations representing these types are introduced into collected network configurations.
    \item A set of real-world misconfigurations verified in actual network configurations.
    \item An exhaustive run of \sysname{} on the entire configuration file of a medium-scale campus network to assess its ability to identify new misconfigurations.
    
We now introduce the setup for our evaluation.
\end{enumerate}
\subsection{Evaluation Setup}
\subsubsection{Context Extraction Hardware Setup}


\textit{System Information}: GNU/Linux Red Hat Enterprise Linux release 8.8 (Ootpa);

\textit{CPU Specifications}: Architecture: x86\_64; CPU(s): 32 (2 threads/core, 16 cores/socket, 1 socket); Model: AMD EPYC 7302P 16-Core Processor; Max MHz: 3000.000; L3 cache: 16384K; NUMA node0 CPU(s): 0-31 

We opt not to use the GPU, as the computational cost of the context extraction and processing tasks was manageable on the CPU. The detailed resource profiling shows that the tasks primarily benefit from parallel CPU threads, and GPU acceleration would not provide significant additional speedup.


\subsubsection{LLM Model Used: GPT-4o} For running the LLM-based detection, we use GPT-4o, OpenAI's most advanced transformer-based model designed for complex multi-step tasks.
\textit{Model Specifications}:
\begin{itemize}
    \item Model: GPT-4o-2024-05-13
    \item Context window: 128,000 tokens 
    \item Max output tokens: 4,096 tokens
    \item Training data Up to October 2023
\end{itemize}

\subsubsection{Prompting and Query Setup}
We use OpenAI’s Chat Completions API to interact with GPT-4o. The system was provided with a structured conversation history to maintain context across multiple queries. For each query, the model was tasked with analyzing the configuration file to detect potential misconfigurations, with instructions tailored to focus on specific misconfiguration types (e.g., syntax issues, policy conflicts) or general misconfigurations. Example prompting, queries, and responses are shown in Figures~\ref{fig:initial_prompt} and ~\ref{fig:feedback_and_response}.

\subsection{Case Study 1: Synthetic Misconfiguration Detection}
In this case study, we broadly categorize router misconfigurations into three types: (1) syntax errors, (2) range violations, and (3) dependency/conflict issues.
\begin{itemize}
    \item \textit{Syntax errors} occur when the configuration syntax does not adhere to the expected format or structure. For example, a missing bracket or misused keyword in a BGP routing policy.
    \item \textit{Range violations} involve parameter values that fall outside the acceptable range. An example would be an MTU value that exceeds the maximum allowed for a specific interface type.
    \item \textit{Dependency/conflict (D/C)} issues arise when different configuration lines are incompatible or contradict each other. For instance, a firewall rule might block traffic that another policy explicitly permits.
\end{itemize}

To evaluate \sysname{}, we first obtain snapshot configurations from Internet2 (Juniper devices) and introduce synthetic misconfigurations representing the three types. For each type, we create four distinct misconfigurations, resulting in a total of 12 misconfigurations. For each misconfiguration, we run \sysname{} by following the two components: (1) treating the misconfigured line as the line under review and extracting all relevant context, and (2) conducting the iterative, sequential prompting process against the model, obtaining the final misconfiguration detection decision.

When forming the prompt, we explicitly instruct the model to look for each type of misconfiguration—syntax, range, or dependency/conflict—individually. This is because the model may request different types of context depending on the specific misconfiguration type it is trying to detect. We report only the results corresponding to the actual misconfiguration type introduced. Importantly, \sysname{} never yielded false positives when the model was instructed to find a misconfiguration type different from the actual type. Additionally, we find that asking the model to search for `general' misconfigurations also led to successful detection, though more context was often requested by the model.

As a baseline, we compare \sysname{} to three representative tools: \textit{Batfish}, a model-checking tool, \textit{Diffy}, a data-mining-based tool, and a partition-based GPT Q\&A model using GPT-4o for fair comparison. We present the specific misconfigurations introduced and the results in Table~\ref{tab:syn_result}, demonstrating how each tool performed in detecting the synthetic misconfigurations across the three categories.

\chase{dont forget about true negatives}
\begin{table}[ht]
\centering
\caption{Number of Cases Detected, Comparative Analysis of Synthetic Misconfiguration Detection Across Tools}
\resizebox{\columnwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|}
\hline
\multirow{2}{*}{\textbf{Type}} & \multirow{2}{*}{\textbf{Cases}} & \multicolumn{4}{c|}{\textbf{Number of Corrected Detected Cases}} \\ \cline{3-6} 
&                                & \textbf{\sysname{}} & \textbf{Partition Prompt} & \textbf{Batfish} & \textbf{Diffy} \\ \hline
Syntax & 4 & 4/4 (100\%) & 2/4 (50\%) & 3/4 (75\%) & 0/4 (0\%) \\ \hline
Range & 4 & 4/4 (100\%) & 2/4 (50\%) & 0/4 (0\%) & 0/4 (0\%) \\ \hline
D/C & 4 & 4/4 (100\%) & 0/4 (0\%) & 2/4 (50\%) & 0/4 (0\%) \\ \hline
\textbf{Total} & \textbf{12} & \textbf{12/12 (100\%)} & \textbf{4/12 (33\%)} & \textbf{5/12 (42\%)} & \textbf{0/12 (0\%)} \\ \hline
\end{tabular}
\label{tab:syn_result}
}
\end{table}


\begin{table}[ht]
\centering
\caption{Synthetic Misconfigurations Introduced and LLM Requested Context for \sysname{}}
\resizebox{\columnwidth}{!}{
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Type} & \textbf{Description} & \textbf{Misconfig} & \textbf{Requested Context}\\ \hline

\multirow{4}{*}{\textbf{Syntax}} 
& Missing brace &..."interfaces": \{"\textcolor{red}{<ge-*"}: & None\\ \cline{2-4}
& Invalid keyword & ..."mtu": \textcolor{red}{"True"}   & \( N(P) \), \( R(P) \)\\ \cline{2-4}
& Incorrect hierarchy & ..."host-name": \textcolor{red}{"\{rtsw.alba-re1\}"}  & \( N(P) \)\\ \cline{2-4}
& Invalid IP address & ..."neighbor \textcolor{red}{192.168.253.1.1}" & \( N(P) \), \( R(P) \)\\ \hline

\multirow{4}{*}{\textbf{Range}}  
& Invalid MTU & ..."mtu": \textcolor{red}{"10000"}  & \( N(P) \), \( R(P) \)\\ \cline{2-4}
& Invalid VLAN ID & ..."vlan-id": \textcolor{red}{"5000"}  & \( N(P) \), \( R(P) \), \( N(R(P)) \) \\ \cline{2-4}
& Invalid AS & ..."autonomous-system \textcolor{red}{70000} & \( N(P) \), \( R(P) \) \\ \cline{2-4}
& Invalid prefix limit & ..."maximum": \textcolor{red}{"200000"} & \( N(P) \), \( R(P) \)  \\ \hline

\multirow{4}{*}{\textbf{D/C}}  
& Non-existent group & ... apply-groups: \textcolor{red}{"L2-LSP-ATTRIBUTES”} & \( N(P) \), \( R(P) \), \( N(R(P)) \) \\ \cline{2-4}
& Policy Conflict & ...community \textcolor{red}{add I2CLOUD-EXTENDED-TARGET}  & \( N(P) \), \( R(P) \), \( N(R(P)) \) \\ \cline{2-4}
& Non-existent filter & ...input-list: \textcolor{red}{"uplink"} & \( N(P) \), \( R(P) \)  \\ \cline{2-4}
& Non-existent policy & ..."export": \textcolor{red}{"OESS-400-300-LOOP} & \( R(P) \)  \\ \hline

\end{tabular}
}
\end{table}


\begin{table}[ht]
\centering
\caption{Example LLM Reasoning for \sysname{}}
\resizebox{\columnwidth}{!}{
\begin{tabular}{|l|l|l|p{8cm}|} % Define a fixed width for the Reason column
\hline
\textbf{Type} & \textbf{Misconfig} & \textbf{errParameter} & \textbf{Reason}\\ \hline

\multirow{3}{*}{\textbf{Syntax}} & \multirow{3}{*}{Missing brace} & \multirow{3}{*}{["<ge-*>"]} & MTU value for 'family inet' is set to 9174 which is less than the interface MTU value of 9192. The MTU for 'family inet' should not be less than the interface MTU.\\\hline

\multirow{3}{*}{\textbf{Range}} & \multirow{3}{*}{Invalid VLAN ID} & \multirow{3}{*}{["vlan-id"]} & The 'vlan-id=5000' is outside the standard VLAN ID range (1-4094) typically supported by Juniper routers. Standard VLAN IDs should be within the range of 1 to 4094."\\\hline

\multirow{5}{*}{\textbf{D/C}} & \multirow{5}{*}{Policy Conflict} & \multirow{5}{*}{" remove-comms-rt"} & "There is a conflict in the configuration under term 'remove-comms-rt' where the action 'community add I2CLOUD-EXTENDED-TARGET' is followed by 'community delete I2CLOUD-EXTENDED-TARGET' which are contradictory actions."\\\hline

\end{tabular}
}
\end{table}


Sequential context prompting allows the gpt model to request for additional context on the configuration lines under review and in sequential it checks for syntax, range, and dependency/conflict misconfigurations:
Context index: 1. Adjacent Configuration Lines, 2. Definitions Related to Configuration Line Under Review, 3. Definitions Related to Adjacent Configuration Lines, 4. Similar Configuration Lines to Configuration Line Under Review
Sectional/Snippet Prompting is used as the baseline where only the section of configuration lines under the review is provided to the gpt model and it only asks for general misconfigurations.

\subsection{Case Study 2: Real-World Misconfiguration Detection}
To reflect real-world misconfigurations, we obtain Juniper router configuration snapshots from a campus network where known misconfigurations regarding port assignment have been found using their graph-based verifier. We instruct the model to detect 'general' misconfigurations when prompting.

A key aspect of this case study is the demonstration of \sysname{}'s flexibility in integrating additional context types under different scenarios. For example, port assignment misconfigurations often require a network-wide view, as they often can only be accurately identified when the context of other devices within the same network is considered. To address this, we introduce an additional, default context type, called `Intra-Router Consistency Context.' This context type mines and evaluates the prevalence of the same parameter-value pair across other devices in the network, providing insights into whether a configuration is common or potentially erroneous.
Example Intra-Router Consistency Context extracted:

\textit{`For the Configuration Line Under Review, the same configuration is found in 189 out of 191 other configuration files. (Significantly lower prevalence may indicate an uncommon or potentially erroneous configuration.'}

We evaluate \sysname{}'s performance on these misconfigured lines and compare the results to the original graph-based verifier, \textit{Batfish}, and the partition-based GPT Q\&A model. The comparison of results is presented in Table X.


\begin{table}[ht]
\centering
\caption{Comparison of Misconfiguration Detection Across Tools}
\resizebox{\columnwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|}
\hline
\textbf{Configuration} & \textbf{Misconfigured} & \textbf{\sysname{}} & \textbf{Partition Prompt} & \textbf{Batfish} & \textbf{Ground Truth} \\ \hline

Port:lag250:vlan\_trunks & Yes (881 and 700 should NOT be in the list) & Correctly Detected & False Negative & False Negative & Correctly Detected \\ \hline
Port:1/1/15:vlan\_tag & Yes (881 should NOT be in the list) & Correctly Detected & False Negative & False Negative & Correctly Detected \\ \hline
Port:1/1/4:vlan\_tag & NO (It is CORRECT for 590 to be in the list) & False Positive & True Negative & True Negative & False Positive \\ \hline
Port:2/1/4:vlan\_tag & NO (It is CORRECT for 590 to be in the list) & False Positive & True Negative & True Negative & False Positive \\ \hline
Port:1/1/21:vlan\_tag & NO (It is CORRECT for 136 to be in the list) & False Positive & True Negative & True Negative & False Positive \\ \hline
Port:1/10/38:vlan\_tag & NO (It is CORRECT for 506 to be in the list) & False Positive & True Negative & True Negative & False Positive \\ \hline

\end{tabular}
}
\end{table}


\subsection{Case Study 3: Large-Scale Network Misconfiguration Detection}
Lastly, we obtain Aruba router configuration snapshots from a medium-sized campus network. Unlike the previous scenarios, this dataset does not contain ground truth misconfigurations. The objective here is twofold: (1) to verify the scalability of \sysname{} when applied to larger network configurations, and (2) to investigate whether \sysname{} can detect potential misconfigurations that have not yet been identified by existing tools.

We perform an exhaustive analysis using \sysname{} across five full configuration files, applying the context mining framework to extract all relevant context for each configuration line. We then prompt the model to identify 'general' misconfigurations, allowing it to dynamically request the necessary context during the iterative prompting phase. The detection results are presented in Table X, highlighting \sysname{}'s ability to uncover new misconfigurations.
